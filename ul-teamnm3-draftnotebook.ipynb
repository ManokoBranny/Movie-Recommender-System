{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Unsupervised Learning Predict - Movie Recommender System Challenge\n© Explore Data Science Academy\n\n---\n### Honour Code\n\nWe, **XXX** {**#Team_NM3**}, confirm - by submitting this document - that the solutions in this notebook are a result of our own work and that we abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n\nNon-compliance with the honour code constitutes a material breach of contract.","metadata":{"id":"3e1ff526"}},{"cell_type":"markdown","source":"<a id=\"cont\"></a>\n\n## Table of Contents\n\n#### Section 1: Data Pre-processing\n\n<a href=#one>1.1 Importing Packages</a>\n\n<a href=#two>1.2 Loading Data</a>\n\n<a href=#three>1.3 Exploratory Data Analysis (EDA)</a>\n\n<a href=#four>1.4 Data Engineering</a>\n\n#### Section 2: Model Development and Analysis\n\n<a href=#five>2.1 Modeling</a>\n\n<a href=#six>2.2 Model Performance</a>\n\n#### Section 3: Model Explanation and Conclusions\n\n<a href=#seven>3.1 Model Explanations</a>\n\n<a href=#seven>3.2 Conclusions</a>","metadata":{"id":"db26ce12"}},{"cell_type":"markdown","source":"# Introduction\nIn today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n\nProviding an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity. \n\nThis Notebook has been adapted and developed by **XXX** - a group of seven students from the July 2022 cohort of the Explore Ai Academy **Data Science** course. We are:\n\n > Josiah Aramide <br>\n > Bongani Mavuso <br>\n > Ndinannyi mukwevho <br>\n > Aniedi Oboho-Etuk <br>\n > Manoko Langa <br>\n > Tshepiso Padi <br>\n > Nsika Masondo <br>\n ","metadata":{"id":"7efcbcb3"}},{"cell_type":"markdown","source":"### Problem Statement\n\nThe client is determined to improve its recommender system service offering to targeted consumer categories based on their movie content rating. \n\nData from the historical viewing experiences, available to the company contains some preference and similarity characteristics that can ensure accurate prediction of consumer behaviour. \n\nBy constructing a recommendation algorithm based on content or collaborative filtering, **XXX** team can develop a solution capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences. This solution can give the company access to immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity.\n","metadata":{"id":"19c635e3"}},{"cell_type":"markdown","source":"### Objectives\n\n**XXX** seeks to achieve the following objectives for the project brief:\n\n- 1. analyse the supplied data;\n- 2. identify underlying patterns and potential errors in the data and clean the existing data set;;\n- 3. determine if additional features can be added to enrich the data set;\n- 4. build a recommendation algorithm based on content or collaborative filtering that is capable of capable of accurately predicting how a user will rate a movie they have not yet viewed;\n- 5. evaluate the accuracy of the best machine learning model; and\n- 6. explain the inner working of the model to a non-technical audience.","metadata":{"id":"15c657c7"}},{"cell_type":"markdown","source":"# Section 1: Data Pre-processing\n\nThis section describes steps for installing dependencies and requirements, initializing the experiment on Comet, importing packages, loading the two datasets - train and test datasets, conducting the exploratory data analysis (EDA) and implementing data engineering.","metadata":{"id":"eb0e4c7a"}},{"cell_type":"markdown","source":" <a id=\"one\"></a>\n## 1.1 Importing Packages\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Importing Packages ⚡ |\n| :--------------------------- |\n| Below are the libraries and tools imported for use in this project. The libraries include:\n   - **numpy**: for working with arrays,\n   - **pandas**: for tansforming and manipulating data in tables,\n   - **matplotlib**: for creating interactive visualisations,\n   - **seaborn**: for making statistical graphs and plots,\n   - **scikit-learn**: for machine learning and statistical modeling, and\n   - **math**: for algebraic notations and calculations.\n\n---","metadata":{"id":"9cac80eb"}},{"cell_type":"code","source":"!pip install comet_ml # Comet installation for Jupyter Notebook/Collab\n!pip install git+https://github.com/microsoft/recommenders.git\n!pip install kneed # knee (/elbow) point detection for cluster optimization\n!pip install tf_slim","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:58:12.776631Z","iopub.execute_input":"2023-01-23T17:58:12.777914Z","iopub.status.idle":"2023-01-23T17:59:45.180822Z","shell.execute_reply.started":"2023-01-23T17:58:12.777768Z","shell.execute_reply":"2023-01-23T17:59:45.179424Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting comet_ml\n  Downloading comet_ml-3.31.23-py3-none-any.whl (450 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.9/450.9 kB\u001b[0m \u001b[31m719.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting requests-toolbelt>=0.8.0\n  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting wurlitzer>=1.0.2\n  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\nRequirement already satisfied: simplejson in /opt/conda/lib/python3.7/site-packages (from comet_ml) (3.18.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from comet_ml) (1.15.0)\nRequirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from comet_ml) (4.6.1)\nRequirement already satisfied: wrapt>=1.11.2 in /opt/conda/lib/python3.7/site-packages (from comet_ml) (1.12.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from comet_ml) (4.13.0)\nCollecting everett[ini]>=1.0.1\n  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\nCollecting dulwich!=0.20.33,>=0.20.6\n  Downloading dulwich-0.21.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (504 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.4/504.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python3.7/site-packages (from comet_ml) (2.28.1)\nRequirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /opt/conda/lib/python3.7/site-packages (from comet_ml) (1.3.3)\nRequirement already satisfied: sentry-sdk>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from comet_ml) (1.12.1)\nCollecting semantic-version>=2.8.0\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from dulwich!=0.20.33,>=0.20.6->comet_ml) (4.1.1)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.7/site-packages (from dulwich!=0.20.33,>=0.20.6->comet_ml) (1.26.13)\nCollecting configobj\n  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (21.4.0)\nRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (5.10.2)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.18.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.18.4->comet_ml) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.18.4->comet_ml) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.18.4->comet_ml) (3.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->comet_ml) (3.8.0)\nInstalling collected packages: everett, wurlitzer, semantic-version, dulwich, configobj, requests-toolbelt, comet_ml\nSuccessfully installed comet_ml-3.31.23 configobj-5.0.8 dulwich-0.21.2 everett-3.1.0 requests-toolbelt-0.10.1 semantic-version-2.10.0 wurlitzer-3.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/microsoft/recommenders.git\n  Cloning https://github.com/microsoft/recommenders.git to /tmp/pip-req-build-umxzq0ls\n  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/recommenders.git /tmp/pip-req-build-umxzq0ls\n  Resolved https://github.com/microsoft/recommenders.git to commit d110a1024d3044ee38059245b81383679d4569ea\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: lightfm<2,>=1.15 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (1.16)\nRequirement already satisfied: lightgbm>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (3.3.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (2.28.1)\nRequirement already satisfied: scipy<2,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (1.7.3)\nRequirement already satisfied: pandas<2,>1.0.3 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (1.3.5)\nCollecting pyyaml<6,>=5.4.1\n  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 kB\u001b[0m \u001b[31m827.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting bottleneck<2,>=1.2.1\n  Downloading Bottleneck-1.3.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.9/355.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (1.21.6)\nRequirement already satisfied: memory-profiler<1,>=0.54.0 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (0.61.0)\nRequirement already satisfied: transformers<5,>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (4.20.1)\nRequirement already satisfied: tqdm<5,>=4.31.1 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (4.64.0)\nCollecting category-encoders<2,>=1.3.0\n  Downloading category_encoders-1.3.0-py2.py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: nltk<4,>=3.4 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (3.8.1)\nRequirement already satisfied: matplotlib<4,>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (3.5.3)\nRequirement already satisfied: scikit-surprise>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (1.1.1)\nRequirement already satisfied: numba<1,>=0.38.1 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (0.55.2)\nRequirement already satisfied: scikit-learn<1.0.3,>=0.22.1 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (1.0.2)\nCollecting jinja2<3.1,>=2\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cornac<2,>=1.1.2\n  Downloading cornac-1.14.2-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: seaborn<1,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (0.11.2)\nCollecting pandera[strategies]>=0.6.5\n  Downloading pandera-0.13.4-py3-none-any.whl (122 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from recommenders==1.1.1) (1.3.3)\nRequirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.7/site-packages (from category-encoders<2,>=1.3.0->recommenders==1.1.1) (0.13.2)\nRequirement already satisfied: patsy>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from category-encoders<2,>=1.3.0->recommenders==1.1.1) (0.5.2)\nCollecting powerlaw\n  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2<3.1,>=2->recommenders==1.1.1) (2.1.1)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm>=2.2.1->recommenders==1.1.1) (0.37.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4,>=2.2.2->recommenders==1.1.1) (1.4.3)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4,>=2.2.2->recommenders==1.1.1) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4,>=2.2.2->recommenders==1.1.1) (22.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4,>=2.2.2->recommenders==1.1.1) (9.1.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4,>=2.2.2->recommenders==1.1.1) (4.33.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4,>=2.2.2->recommenders==1.1.1) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4,>=2.2.2->recommenders==1.1.1) (2.8.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from memory-profiler<1,>=0.54.0->recommenders==1.1.1) (5.9.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk<4,>=3.4->recommenders==1.1.1) (1.0.1)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk<4,>=3.4->recommenders==1.1.1) (2021.11.10)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk<4,>=3.4->recommenders==1.1.1) (8.1.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba<1,>=0.38.1->recommenders==1.1.1) (59.8.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba<1,>=0.38.1->recommenders==1.1.1) (0.38.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2,>1.0.3->recommenders==1.1.1) (2022.1)\nCollecting typing-inspect>=0.6.0\n  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.7/site-packages (from pandera[strategies]>=0.6.5->recommenders==1.1.1) (1.12.1)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from pandera[strategies]>=0.6.5->recommenders==1.1.1) (1.8.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from pandera[strategies]>=0.6.5->recommenders==1.1.1) (4.1.1)\nCollecting hypothesis>=5.41.1\n  Downloading hypothesis-6.64.0-py3-none-any.whl (401 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.1/401.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->recommenders==1.1.1) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->recommenders==1.1.1) (1.26.13)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->recommenders==1.1.1) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->recommenders==1.1.1) (2022.12.7)\nRequirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from retrying>=1.3.3->recommenders==1.1.1) (1.15.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.0.3,>=0.22.1->recommenders==1.1.1) (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5,>=2.5.0->recommenders==1.1.1) (3.7.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5,>=2.5.0->recommenders==1.1.1) (0.12.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5,>=2.5.0->recommenders==1.1.1) (4.13.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers<5,>=2.5.0->recommenders==1.1.1) (0.10.1)\nRequirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from hypothesis>=5.41.1->pandera[strategies]>=0.6.5->recommenders==1.1.1) (2.4.0)\nRequirement already satisfied: exceptiongroup>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from hypothesis>=5.41.1->pandera[strategies]>=0.6.5->recommenders==1.1.1) (1.1.0)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from hypothesis>=5.41.1->pandera[strategies]>=0.6.5->recommenders==1.1.1) (21.4.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from typing-inspect>=0.6.0->pandera[strategies]>=0.6.5->recommenders==1.1.1) (0.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5,>=2.5.0->recommenders==1.1.1) (3.8.0)\nRequirement already satisfied: mpmath in /opt/conda/lib/python3.7/site-packages (from powerlaw->cornac<2,>=1.1.2->recommenders==1.1.1) (1.2.1)\nBuilding wheels for collected packages: recommenders\n  Building wheel for recommenders (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for recommenders: filename=recommenders-1.1.1-py3-none-any.whl size=351205 sha256=bc41c1357c7caa249a88937991c2ccec931aadc8468de15d39233a2e6ef5805d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-4x0cdr7z/wheels/b9/06/d5/12342ff81379a3bbafda343950b5c64869d2e5dbfd348685ea\nSuccessfully built recommenders\nInstalling collected packages: typing-inspect, pyyaml, jinja2, hypothesis, bottleneck, powerlaw, pandera, cornac, category-encoders, recommenders\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0\n    Uninstalling PyYAML-6.0:\n      Successfully uninstalled PyYAML-6.0\n  Attempting uninstall: jinja2\n    Found existing installation: Jinja2 3.1.2\n    Uninstalling Jinja2-3.1.2:\n      Successfully uninstalled Jinja2-3.1.2\n  Attempting uninstall: category-encoders\n    Found existing installation: category-encoders 2.5.1.post0\n    Uninstalling category-encoders-2.5.1.post0:\n      Successfully uninstalled category-encoders-2.5.1.post0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nnnabla 1.32.0 requires protobuf<=3.19.4; platform_system != \"Windows\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bottleneck-1.3.6 category-encoders-1.3.0 cornac-1.14.2 hypothesis-6.64.0 jinja2-3.0.3 pandera-0.13.4 powerlaw-1.5 pyyaml-5.4.1 recommenders-1.1.1 typing-inspect-0.8.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting kneed\n  Downloading kneed-0.8.2-py3-none-any.whl (10 kB)\nRequirement already satisfied: numpy>=1.14.2 in /opt/conda/lib/python3.7/site-packages (from kneed) (1.21.6)\nRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from kneed) (1.7.3)\nInstalling collected packages: kneed\nSuccessfully installed kneed-0.8.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting tf_slim\n  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m596.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from tf_slim) (0.15.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\nInstalling collected packages: tf_slim\nSuccessfully installed tf_slim-1.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Libraries for data loading, data manipulation and data visulisation \nimport numpy as np   # for working with \nimport pandas as pd  # for data processing, CSV file I/O (e.g. pd.read_csv)\nfrom recommenders.datasets.python_splitters import python_chrono_split\nimport matplotlib.pyplot as plt  # for making visualisations and plots\nimport seaborn as sns\nimport datetime as dt\nimport math\nimport time\nimport pickle\n%matplotlib inline\n\n# Libraries for collecting experiment parameters\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport comet_ml\nfrom comet_ml import Experiment\n\n# Libraries for data engineering and model building\nfrom sklearn import preprocessing\nfrom kneed import KneeLocator\nfrom sklearn.preprocessing import StandardScaler # for standardization\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.cluster import KMeans\n\n# Libraries for Building Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import mutual_info_regression #determine mutual info\nfrom sklearn.datasets import make_blobs\nfrom surprise import Reader, Dataset, SVD\nfrom surprise.model_selection import cross_validate\nfrom recommenders.models.ncf.ncf_singlenode import NCF\n\nimport sys\nfrom sys import exc_info\nimport ast","metadata":{"id":"ebba6e7e","execution":{"iopub.status.busy":"2023-01-23T17:59:53.076944Z","iopub.execute_input":"2023-01-23T17:59:53.077349Z","iopub.status.idle":"2023-01-23T17:59:59.499114Z","shell.execute_reply.started":"2023-01-23T17:59:53.077301Z","shell.execute_reply":"2023-01-23T17:59:59.498138Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the Kaggle \"../input/\" directory.\n# Thus, running this code cell will list all files under the input directory\n# These file paths can be used to load the datasets into this notebook\nfor dirname, _, filenames in os.walk('/kaggle/input/edsa-movie-recommendation-predict'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:59:59.503237Z","iopub.execute_input":"2023-01-23T17:59:59.503841Z","iopub.status.idle":"2023-01-23T17:59:59.510122Z","shell.execute_reply.started":"2023-01-23T17:59:59.503808Z","shell.execute_reply":"2023-01-23T17:59:59.508786Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/edsa-movie-recommendation-predict/sample_submission.csv\n/kaggle/input/edsa-movie-recommendation-predict/movies.csv\n/kaggle/input/edsa-movie-recommendation-predict/imdb_data.csv\n/kaggle/input/edsa-movie-recommendation-predict/genome_tags.csv\n/kaggle/input/edsa-movie-recommendation-predict/genome_scores.csv\n/kaggle/input/edsa-movie-recommendation-predict/train.csv\n/kaggle/input/edsa-movie-recommendation-predict/test.csv\n/kaggle/input/edsa-movie-recommendation-predict/tags.csv\n/kaggle/input/edsa-movie-recommendation-predict/links.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create an instance of Comet experiment with TeamNM3's API key\nexperiment = Experiment(\n    api_key=\"RpnzF8DcMSor3mXqAfEQqsXjv\",\n    project_name=\"unsupervised-learning-predict\",\n    workspace=\"teamnm3\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:59:59.747816Z","iopub.execute_input":"2023-01-23T17:59:59.748804Z","iopub.status.idle":"2023-01-23T18:00:04.342104Z","shell.execute_reply.started":"2023-01-23T17:59:59.748762Z","shell.execute_reply":"2023-01-23T18:00:04.340619Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\nCOMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\nCOMET INFO: Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\nCOMET INFO: Experiment is live on comet.com https://www.comet.com/teamnm3/unsupervised-learning-predict/48a15b5140ea4c97b605d099795f05de\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"two\"></a>\n## 1.2 Loading the Data\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Loading the data ⚡ |\n| :--------------------------- |\n| In this section, data is loaded from the **xxxxx** made available to **TeamNM3** by the client, **Explore-AI**. This involves reading the data from the `.csv` file format into a Pandas dataframe. The Pandas dataframe allows for easy views and manipulations of the data in the form of tables and can be combined with other python libraries like numpy for desirable results. |\n\n---","metadata":{"id":"b16bd964"}},{"cell_type":"code","source":"# Store datasets in a Pandas Dataframe\ndf_train = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/train.csv')\ndf_test = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/test.csv')\ndf_mov = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/movies.csv')\ndf_gs = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/genome_scores.csv')\ndf_gt = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/genome_tags.csv')\ndf_imdb = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/imdb_data.csv')\ndf_links = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/links.csv')\ndf_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/tags.csv')","metadata":{"id":"yIS-Xiek0khY","execution":{"iopub.status.busy":"2023-01-23T18:00:04.346284Z","iopub.execute_input":"2023-01-23T18:00:04.347257Z","iopub.status.idle":"2023-01-23T18:00:26.125896Z","shell.execute_reply.started":"2023-01-23T18:00:04.347203Z","shell.execute_reply":"2023-01-23T18:00:26.124732Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"three\"></a>\n## 1.3 Exploratory Data Analysis (EDA)\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Exploratory data analysis ⚡ |\n| :--------------------------- |\n| In this section, an in-depth analysis (graphical and non-graphical) of the supplied data is conducted. This includes: \n - viewing the matrix to determine the dimensions of the data;\n - identifying the features and target;\n - investigating the formatting of the data (types, nulls etc.)\n - viewing the xxx;\n - identifying the xxx;\n - analysing the xxx;\n .|\n\n---","metadata":{"id":"54bdd2f3"}},{"cell_type":"markdown","source":"### 1.3.1 Viewing the matrix (dimensions) of the data\nFirst, it is necessary to view the matrix of the supplied datasets to see the total number of rows, number of columns, the content and the format (datatypes) of the features within each of the datasets.","metadata":{}},{"cell_type":"code","source":"# Create a function to return the matrix of datasets\ndef data_matrix(df, label):\n    '''\n    df: (pd) pandas dataframe of the dataset\n    label: (str) a string to describe the dataset name\n    '''\n    df.shape\n    nRow, nCol = df.shape\n    print(f'There are {nRow} rows and {nCol} columns in the {label} dataset')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:45:38.474637Z","iopub.execute_input":"2023-01-23T17:45:38.475171Z","iopub.status.idle":"2023-01-23T17:45:38.482760Z","shell.execute_reply.started":"2023-01-23T17:45:38.475126Z","shell.execute_reply":"2023-01-23T17:45:38.480855Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_matrix(df_train, 'train'), # Train dataset Matrix\ndata_matrix(df_test, 'test'), # Test dataset Matrix\ndata_matrix(df_mov, 'movies'), # Movie dataset Matrix\ndata_matrix(df_gs, 'genome_scores') # Genome scores dataset Matrix","metadata":{"id":"1578b772","outputId":"6c76578b-bdf1-45ed-f263-97001fb100db","execution":{"iopub.status.busy":"2023-01-23T17:45:39.222656Z","iopub.execute_input":"2023-01-23T17:45:39.223040Z","iopub.status.idle":"2023-01-23T17:45:39.232674Z","shell.execute_reply.started":"2023-01-23T17:45:39.223015Z","shell.execute_reply":"2023-01-23T17:45:39.231313Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"There are 10000038 rows and 4 columns in the train dataset\nThere are 5000019 rows and 2 columns in the test dataset\nThere are 62423 rows and 3 columns in the movies dataset\nThere are 15584448 rows and 3 columns in the genome_scores dataset\n","output_type":"stream"}]},{"cell_type":"code","source":"data_matrix(df_gt, 'genome_tags') # Genome tags dataset Matrix\ndata_matrix(df_imdb, 'imdb') # IMDB dataset Matrix\ndata_matrix(df_links, 'links') # Links dataset Matrix\ndata_matrix(df_tags, 'tags') # Tags dataset Matrix","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:45:40.223217Z","iopub.execute_input":"2023-01-23T17:45:40.223612Z","iopub.status.idle":"2023-01-23T17:45:40.234618Z","shell.execute_reply.started":"2023-01-23T17:45:40.223586Z","shell.execute_reply":"2023-01-23T17:45:40.232895Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"There are 1128 rows and 2 columns in the genome_tags dataset\nThere are 27278 rows and 6 columns in the imdb dataset\nThere are 62423 rows and 3 columns in the links dataset\nThere are 1093360 rows and 4 columns in the tags dataset\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### OBSERVATION\n- As the results show, the train dataset contains a little over **10 million** rows of data** in 4 columns of features. \n- The test dataset contains exactly half of that number of observations (**5,000,019**) with only 2 columns of features.\n\n- Other datasets contain ...\n\nNext, a peek view of some of the rows in the dataset should be of interest. This can be accomplished with the `pd.head()` command as seen in the code cell below. The command can take an argument specifying the number of rows to view (10 in this example), otherwise it returns the first 5 rows by default. ","metadata":{}},{"cell_type":"code","source":"# View top of datasets, train set\n\ndf_train.head(10)","metadata":{"id":"H8-q8ZB8unwy","outputId":"37e6ce69-1a94-4ca6-a2c1-f4a97c0a087f","execution":{"iopub.status.busy":"2023-01-23T17:45:42.129231Z","iopub.execute_input":"2023-01-23T17:45:42.129608Z","iopub.status.idle":"2023-01-23T17:45:42.158480Z","shell.execute_reply.started":"2023-01-23T17:45:42.129580Z","shell.execute_reply":"2023-01-23T17:45:42.156132Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   userId  movieId  rating   timestamp\n0    5163    57669     4.0  1518349992\n1  106343        5     4.5  1206238739\n2  146790     5459     5.0  1076215539\n3  106362    32296     2.0  1423042565\n4    9041      366     3.0   833375837\n5  120949    81768     3.0  1289595242\n6   19630    62049     4.0  1246729817\n7   21066     2282     1.0   945785907\n8  117563   120474     4.0  1515108225\n9  144018     1997     5.0  1109967647","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5163</td>\n      <td>57669</td>\n      <td>4.0</td>\n      <td>1518349992</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106343</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>1206238739</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>146790</td>\n      <td>5459</td>\n      <td>5.0</td>\n      <td>1076215539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106362</td>\n      <td>32296</td>\n      <td>2.0</td>\n      <td>1423042565</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9041</td>\n      <td>366</td>\n      <td>3.0</td>\n      <td>833375837</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>120949</td>\n      <td>81768</td>\n      <td>3.0</td>\n      <td>1289595242</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>19630</td>\n      <td>62049</td>\n      <td>4.0</td>\n      <td>1246729817</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>21066</td>\n      <td>2282</td>\n      <td>1.0</td>\n      <td>945785907</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>117563</td>\n      <td>120474</td>\n      <td>4.0</td>\n      <td>1515108225</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>144018</td>\n      <td>1997</td>\n      <td>5.0</td>\n      <td>1109967647</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# looking at the test set\ndf_mov.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:45:43.050873Z","iopub.execute_input":"2023-01-23T17:45:43.051296Z","iopub.status.idle":"2023-01-23T17:45:43.064722Z","shell.execute_reply.started":"2023-01-23T17:45:43.051269Z","shell.execute_reply":"2023-01-23T17:45:43.062780Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_gs.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:45:43.303132Z","iopub.execute_input":"2023-01-23T17:45:43.303542Z","iopub.status.idle":"2023-01-23T17:45:43.318072Z","shell.execute_reply.started":"2023-01-23T17:45:43.303514Z","shell.execute_reply":"2023-01-23T17:45:43.315458Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   movieId  tagId  relevance\n0        1      1    0.02875\n1        1      2    0.02375\n2        1      3    0.06250\n3        1      4    0.07575\n4        1      5    0.14075","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>tagId</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.02875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.02375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.06250</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.07575</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.14075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_imdb.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T17:45:44.423854Z","iopub.execute_input":"2023-01-23T17:45:44.424265Z","iopub.status.idle":"2023-01-23T17:45:44.439487Z","shell.execute_reply.started":"2023-01-23T17:45:44.424238Z","shell.execute_reply":"2023-01-23T17:45:44.437973Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   movieId                                         title_cast  \\\n0        1  Tom Hanks|Tim Allen|Don Rickles|Jim Varney|Wal...   \n1        2  Robin Williams|Jonathan Hyde|Kirsten Dunst|Bra...   \n2        3  Walter Matthau|Jack Lemmon|Sophia Loren|Ann-Ma...   \n3        4  Whitney Houston|Angela Bassett|Loretta Devine|...   \n4        5  Steve Martin|Diane Keaton|Martin Short|Kimberl...   \n\n              director  runtime       budget  \\\n0        John Lasseter     81.0  $30,000,000   \n1   Jonathan Hensleigh    104.0  $65,000,000   \n2  Mark Steven Johnson    101.0  $25,000,000   \n3       Terry McMillan    124.0  $16,000,000   \n4       Albert Hackett    106.0  $30,000,000   \n\n                                       plot_keywords  \n0                   toy|rivalry|cowboy|cgi animation  \n1                   board game|adventurer|fight|game  \n2                         boat|lake|neighbor|rivalry  \n3  black american|husband wife relationship|betra...  \n4                    fatherhood|doberman|dog|mansion  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title_cast</th>\n      <th>director</th>\n      <th>runtime</th>\n      <th>budget</th>\n      <th>plot_keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Tom Hanks|Tim Allen|Don Rickles|Jim Varney|Wal...</td>\n      <td>John Lasseter</td>\n      <td>81.0</td>\n      <td>$30,000,000</td>\n      <td>toy|rivalry|cowboy|cgi animation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Robin Williams|Jonathan Hyde|Kirsten Dunst|Bra...</td>\n      <td>Jonathan Hensleigh</td>\n      <td>104.0</td>\n      <td>$65,000,000</td>\n      <td>board game|adventurer|fight|game</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Walter Matthau|Jack Lemmon|Sophia Loren|Ann-Ma...</td>\n      <td>Mark Steven Johnson</td>\n      <td>101.0</td>\n      <td>$25,000,000</td>\n      <td>boat|lake|neighbor|rivalry</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Whitney Houston|Angela Bassett|Loretta Devine|...</td>\n      <td>Terry McMillan</td>\n      <td>124.0</td>\n      <td>$16,000,000</td>\n      <td>black american|husband wife relationship|betra...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Steve Martin|Diane Keaton|Martin Short|Kimberl...</td>\n      <td>Albert Hackett</td>\n      <td>106.0</td>\n      <td>$30,000,000</td>\n      <td>fatherhood|doberman|dog|mansion</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### OBSERVATION\n- The output indicates that the `xxx` column (features) contains xxx. These will need to be addressed during the feature engineering phase in order to derive any usefulness from them.\n","metadata":{}},{"cell_type":"code","source":"# Data Types and Non-null count \ndf_train.info()","metadata":{"id":"W8m9wlQ_3LHq","outputId":"2db55cc2-fe39-435c-9a4b-d3d1a2b9dd6b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirm the Non-null count for train data\ndf_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirm the Non-null count for imdb data\ndf_imdb.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary Statistics of our train dataset\ndf_train.describe()","metadata":{"id":"QWa6XquV3K8r","outputId":"10a111d5-e804-41cc-90c5-a42c49d702b2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OBSERVATION\n- From above, it can be observed that the dataset appears to have no missing values. That is, the count of non-null rows equals the expected count of entries in the columns. ","metadata":{"id":"6XQcByLz3bDi"}},{"cell_type":"code","source":"# check for duplicates in the train dataset\ndf_train[df_train.duplicated(keep=False)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OBSERVATION\n - It is immediately obvious that there are no duplicates in the train dataset, as seen from above output statement","metadata":{}},{"cell_type":"markdown","source":"### 1.3.2 Visualisation: Histogram and Distribution plot of features (showing outliers)","metadata":{}},{"cell_type":"code","source":"# Visualize the distribution of each variable in the train dataset\nplt.figure(figsize=(12,16))\nfor i, j in enumerate(df_train.describe().columns): # enumerate by columns\n    plt.subplot(3,2, i+1)\n    sns.distplot(x=df_train[j])\n    plt.xlabel(j)\n    plt.axvline(x=df_train[j].mean(),color='red',label='mean')\n    plt.axvline(x=df_train[j].median(),color='blue',label='median',ls='--',lw=2.5)\n    plt.title('{} Distribution'.format(j))\n    plt.legend(['mean', 'median'])\n    \n    # plt.subplots_adjust(wspace=.2, hspace=.5)\n    plt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OBSERVATION\n\nWe observe that;\n- In the userId and rating column graphs the medians and the means are the same\n- whereas, in the movieId and timestamp graphs the means and medians are different\n- In the movieId graph the median falls at the right outside of the left-skewed curve. This tells us that majority of movies were rated less than 20,000 times. We may consider those at the right of the median line as outliers","metadata":{}},{"cell_type":"markdown","source":"### 1.3.3 Visualisation: Boxplot of features (showing outliers)","metadata":{}},{"cell_type":"code","source":"# Next, Visualize the boxplot of each variable in the train dataset.\nplt.figure(figsize=(12,10))\nfor i, j in enumerate(df_train.describe().columns):\n    plt.subplot(3,2, i+1)\n    sns.boxplot(x=df_train[j])\n    plt.title('{} Boxplot'.format(j))\n    plt.tight_layout()\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The __boxplot__ puts our earlier observation into a better perspective.\n- we can see that both userId and rating have mean and medians as same value.\n- values above the median in movieId can be considered outliers","metadata":{}},{"cell_type":"code","source":"# compare features with similar boxplots on a scatter plot\nfig = plt.figure(figsize=(8,6))\nsns.scatterplot(x=df_train.userId, y=df_train.timestamp)\nplt.title('timestamp vs. userId Scatterplot')\nplt.savefig('scatter.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OBSERVATION\n\n- Each dot is a userId rating along the time on the y-axis.\n- The bigger the dot the higher the rating","metadata":{}},{"cell_type":"markdown","source":"Data should be scaled to make sense of the multivariate trends across features","metadata":{}},{"cell_type":"code","source":"# check correlation among variables (multivariate analysis)\npairplot = sns.pairplot(df_train, corner=True)\nplt.show(pairplot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The __pairplot__ gives us the histogram and scatter plots in one graph.\n\nThe above graphs compare the pairplots of the train dataset taking into account the columns of the datasets","metadata":{}},{"cell_type":"code","source":"# heatmap view of correlation among variables in the train dataset\ncorrelation_metrics=df_train.corr()\nfig = plt.figure(figsize=(14,9))\nsns.heatmap(correlation_metrics,square=True, annot=True, vmax=1, vmin=-1, cmap='RdBu')\nplt.title('Correlation Between Variables', size=14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OBSERVATION\n\n- The correlation graph shows the relationship degree amongst the vriable columns\n- movieId and timestamp seems to have the stronger correlation","metadata":{}},{"cell_type":"markdown","source":"<a id=\"four\"></a>\n## 1.4 Data Engineering\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Data engineering ⚡ |\n| :--------------------------- |\n| In this section we conduct our feature engineering to: \n- clean identified errors from the dataset;\n- enrich the dataset by creating new features;\n- split the dataset into training and validation sets for use by selected models;\n- standardize the dataset;\n- \n- \n\nThese steps follow the insights that were gathered earlier during the EDA phase.|\n\n---","metadata":{"id":"6098c567"}},{"cell_type":"markdown","source":"### 1.4.1 Preprocessing 1: Cleaning and Filtering (with Feature selection)\nThe first step is to begin organising the data cleaning exercise by building smart functions so that these can be recalled for cleaning both the training and testing datasets. Without this logical flow of cleaning the data, the exercise can quickly get very messy.","metadata":{}},{"cell_type":"markdown","source":"The __df_mov__ dataset","metadata":{}},{"cell_type":"code","source":"df_mov.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:00:26.127551Z","iopub.execute_input":"2023-01-23T18:00:26.127890Z","iopub.status.idle":"2023-01-23T18:00:26.150845Z","shell.execute_reply.started":"2023-01-23T18:00:26.127860Z","shell.execute_reply":"2023-01-23T18:00:26.149585Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We observe the year 1995 attached to the top 5 movies. Most movie titles are in same format.\n\nLet us strip off the year","metadata":{}},{"cell_type":"code","source":"# removing years in title\ndf_mov['title'] = df_mov.title.str.replace('(\\(\\d\\d\\d\\d\\))', '')\ndf_mov['title'] = df_mov['title'].apply(lambda x: x.strip())\ndf_mov.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:00:27.314909Z","iopub.execute_input":"2023-01-23T18:00:27.316031Z","iopub.status.idle":"2023-01-23T18:00:27.415591Z","shell.execute_reply.started":"2023-01-23T18:00:27.315990Z","shell.execute_reply":"2023-01-23T18:00:27.414374Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   movieId                        title  \\\n0        1                    Toy Story   \n1        2                      Jumanji   \n2        3             Grumpier Old Men   \n3        4            Waiting to Exhale   \n4        5  Father of the Bride Part II   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Select some features based on the timestamp median, simply to run a base model","metadata":{}},{"cell_type":"code","source":"# filter the train dataset to reduce the size\ndf_train_filtered = df_train[df_train.movieId < df_train.userId.median()][:]\ndf_train_filtered","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:18:59.098138Z","iopub.execute_input":"2023-01-23T19:18:59.098731Z","iopub.status.idle":"2023-01-23T19:18:59.822887Z","shell.execute_reply.started":"2023-01-23T19:18:59.098685Z","shell.execute_reply":"2023-01-23T19:18:59.821860Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"          userId  movieId  rating   timestamp\n0           5163    57669     4.0  1518349992\n1         106343        5     4.5  1206238739\n2         146790     5459     5.0  1076215539\n3         106362    32296     2.0  1423042565\n4           9041      366     3.0   833375837\n...          ...      ...     ...         ...\n10000032  132019     1914     4.0   938800640\n10000034  140078      553     3.0  1002580977\n10000035  154807    56782     4.0  1227674807\n10000036   85805      327     4.0  1479921530\n10000037  139457     1009     4.0   858984862\n\n[8965356 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5163</td>\n      <td>57669</td>\n      <td>4.0</td>\n      <td>1518349992</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106343</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>1206238739</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>146790</td>\n      <td>5459</td>\n      <td>5.0</td>\n      <td>1076215539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106362</td>\n      <td>32296</td>\n      <td>2.0</td>\n      <td>1423042565</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9041</td>\n      <td>366</td>\n      <td>3.0</td>\n      <td>833375837</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10000032</th>\n      <td>132019</td>\n      <td>1914</td>\n      <td>4.0</td>\n      <td>938800640</td>\n    </tr>\n    <tr>\n      <th>10000034</th>\n      <td>140078</td>\n      <td>553</td>\n      <td>3.0</td>\n      <td>1002580977</td>\n    </tr>\n    <tr>\n      <th>10000035</th>\n      <td>154807</td>\n      <td>56782</td>\n      <td>4.0</td>\n      <td>1227674807</td>\n    </tr>\n    <tr>\n      <th>10000036</th>\n      <td>85805</td>\n      <td>327</td>\n      <td>4.0</td>\n      <td>1479921530</td>\n    </tr>\n    <tr>\n      <th>10000037</th>\n      <td>139457</td>\n      <td>1009</td>\n      <td>4.0</td>\n      <td>858984862</td>\n    </tr>\n  </tbody>\n</table>\n<p>8965356 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# drop the rating column from the filtered train dataset\ndf_tr_no_rating = df_train_filtered.drop(['rating', 'timestamp'], axis=1)\ndf_tr_no_rating","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:19:21.617102Z","iopub.execute_input":"2023-01-23T19:19:21.617871Z","iopub.status.idle":"2023-01-23T19:19:21.689543Z","shell.execute_reply.started":"2023-01-23T19:19:21.617834Z","shell.execute_reply":"2023-01-23T19:19:21.688474Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"          userId  movieId\n0           5163    57669\n1         106343        5\n2         146790     5459\n3         106362    32296\n4           9041      366\n...          ...      ...\n10000032  132019     1914\n10000034  140078      553\n10000035  154807    56782\n10000036   85805      327\n10000037  139457     1009\n\n[8965356 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5163</td>\n      <td>57669</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106343</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>146790</td>\n      <td>5459</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106362</td>\n      <td>32296</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9041</td>\n      <td>366</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10000032</th>\n      <td>132019</td>\n      <td>1914</td>\n    </tr>\n    <tr>\n      <th>10000034</th>\n      <td>140078</td>\n      <td>553</td>\n    </tr>\n    <tr>\n      <th>10000035</th>\n      <td>154807</td>\n      <td>56782</td>\n    </tr>\n    <tr>\n      <th>10000036</th>\n      <td>85805</td>\n      <td>327</td>\n    </tr>\n    <tr>\n      <th>10000037</th>\n      <td>139457</td>\n      <td>1009</td>\n    </tr>\n  </tbody>\n</table>\n<p>8965356 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"__Copy Dataset__\n\nTo preserve the main dataset we create a copy for our modeling","metadata":{}},{"cell_type":"code","source":"ratings = df_train_filtered.copy()\n\nmovies_list = np.unique(ratings['movieId'])[:]\nratings = ratings.loc[ratings['movieId'].isin(movies_list)]\nprint('Shape of ratings dataset is: ',ratings.shape, '\\n')\nprint('Max values in dataset are \\n',ratings.max(), '\\n')\nprint('Min values in dataset are \\n',ratings.min(), '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:19:23.278035Z","iopub.execute_input":"2023-01-23T19:19:23.278448Z","iopub.status.idle":"2023-01-23T19:19:24.643351Z","shell.execute_reply.started":"2023-01-23T19:19:23.278417Z","shell.execute_reply":"2023-01-23T19:19:24.642390Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Shape of ratings dataset is:  (8965356, 4) \n\nMax values in dataset are \n userId       1.625410e+05\nmovieId      8.090800e+04\nrating       5.000000e+00\ntimestamp    1.574327e+09\ndtype: float64 \n\nMin values in dataset are \n userId               1.0\nmovieId              1.0\nrating               0.5\ntimestamp    789652009.0\ndtype: float64 \n\n","output_type":"stream"}]},{"cell_type":"code","source":"users_list = np.unique(ratings['userId'])[:]\nratings = ratings.loc[ratings['userId'].isin(users_list)]\nprint('Shape of ratings dataset is: ',ratings.shape, '\\n')\nprint('Max values in dataset are \\n',ratings.max(), '\\n')\nprint('Min values in dataset are \\n',ratings.min(), '\\n')\nprint('Total Users: ', np.unique(ratings['userId']).shape[0])\nprint('Total Movies which are rated by 100 users: ', np.unique(ratings['movieId']).shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:19:25.950855Z","iopub.execute_input":"2023-01-23T19:19:25.951603Z","iopub.status.idle":"2023-01-23T19:19:28.956201Z","shell.execute_reply.started":"2023-01-23T19:19:25.951552Z","shell.execute_reply":"2023-01-23T19:19:28.955333Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Shape of ratings dataset is:  (8965356, 4) \n\nMax values in dataset are \n userId       1.625410e+05\nmovieId      8.090800e+04\nrating       5.000000e+00\ntimestamp    1.574327e+09\ndtype: float64 \n\nMin values in dataset are \n userId               1.0\nmovieId              1.0\nrating               0.5\ntimestamp    789652009.0\ndtype: float64 \n\nTotal Users:  162480\nTotal Movies which are rated by 100 users:  15152\n","output_type":"stream"}]},{"cell_type":"markdown","source":"And finally, its done. We have a dataset of shape (447,4) which inlcudes 4+ ratings of 108 movies by 100 users. As we were started with 100 movies but when we extracted it for only first 100 users, it looks like that the movies from 84-200 were not rated by first 100 users.\n\nAs, now we are not worried for ratings column and further we have supposed that each movie which is rated 4+ by user is of his/her interest. So, if a movie is an interest of user 1 then that movie will also be interest of another user 2 of same taste. Now, we can drop this column as each movie is a fovourite for every user.","metadata":{}},{"cell_type":"code","source":"# drop the rating column from the filtered train dataset\ndf_tr_no_rating = ratings.drop(['rating', 'timestamp'], axis=1)\ndf_tr_no_rating","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:19:36.432223Z","iopub.execute_input":"2023-01-23T19:19:36.432676Z","iopub.status.idle":"2023-01-23T19:19:36.498279Z","shell.execute_reply.started":"2023-01-23T19:19:36.432640Z","shell.execute_reply":"2023-01-23T19:19:36.497240Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"          userId  movieId\n0           5163    57669\n1         106343        5\n2         146790     5459\n3         106362    32296\n4           9041      366\n...          ...      ...\n10000032  132019     1914\n10000034  140078      553\n10000035  154807    56782\n10000036   85805      327\n10000037  139457     1009\n\n[8965356 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5163</td>\n      <td>57669</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106343</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>146790</td>\n      <td>5459</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106362</td>\n      <td>32296</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9041</td>\n      <td>366</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10000032</th>\n      <td>132019</td>\n      <td>1914</td>\n    </tr>\n    <tr>\n      <th>10000034</th>\n      <td>140078</td>\n      <td>553</td>\n    </tr>\n    <tr>\n      <th>10000035</th>\n      <td>154807</td>\n      <td>56782</td>\n    </tr>\n    <tr>\n      <th>10000036</th>\n      <td>85805</td>\n      <td>327</td>\n    </tr>\n    <tr>\n      <th>10000037</th>\n      <td>139457</td>\n      <td>1009</td>\n    </tr>\n  </tbody>\n</table>\n<p>8965356 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We then save to a .csv file format","metadata":{}},{"cell_type":"code","source":"df_tr_no_rating.to_csv('new_ratings.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:19:38.976710Z","iopub.execute_input":"2023-01-23T19:19:38.977476Z","iopub.status.idle":"2023-01-23T19:19:52.593682Z","shell.execute_reply.started":"2023-01-23T19:19:38.977439Z","shell.execute_reply":"2023-01-23T19:19:52.592627Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"### 1.4.2 Preprocessing 2 - Standardization\nIn this step, the task is to complete preprocessing on the train and test datasets ahead of modeling. First, ","metadata":{}},{"cell_type":"markdown","source":"#### 1.4.2.1 Standardizing the features\nCreate a `stand` function to complete the task of standardization.","metadata":{}},{"cell_type":"code","source":"# defining global scaler objects\nss = StandardScaler()\nrs = RobustScaler()\nmm = MinMaxScaler()\n\n# scale the dataframe\ntrain_scaled = ss.fit_transform(df_tr_no_rating)\nscaled_df_train = pd.DataFrame(train_scaled, columns=['userId', 'movieId'])\nscaled_df_train","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:19:52.595509Z","iopub.execute_input":"2023-01-23T19:19:52.595890Z","iopub.status.idle":"2023-01-23T19:19:52.934934Z","shell.execute_reply.started":"2023-01-23T19:19:52.595859Z","shell.execute_reply":"2023-01-23T19:19:52.933813Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"           userId   movieId\n0       -1.626027  2.500814\n1        0.535863 -0.529269\n2        1.400086 -0.242676\n3        0.536269  1.167533\n4       -1.543167 -0.510299\n...           ...       ...\n8965351  1.084477 -0.428956\n8965352  1.256672 -0.500473\n8965353  1.571383  2.454204\n8965354  0.097033 -0.512348\n8965355  1.243403 -0.476511\n\n[8965356 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.626027</td>\n      <td>2.500814</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.535863</td>\n      <td>-0.529269</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.400086</td>\n      <td>-0.242676</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.536269</td>\n      <td>1.167533</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.543167</td>\n      <td>-0.510299</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8965351</th>\n      <td>1.084477</td>\n      <td>-0.428956</td>\n    </tr>\n    <tr>\n      <th>8965352</th>\n      <td>1.256672</td>\n      <td>-0.500473</td>\n    </tr>\n    <tr>\n      <th>8965353</th>\n      <td>1.571383</td>\n      <td>2.454204</td>\n    </tr>\n    <tr>\n      <th>8965354</th>\n      <td>0.097033</td>\n      <td>-0.512348</td>\n    </tr>\n    <tr>\n      <th>8965355</th>\n      <td>1.243403</td>\n      <td>-0.476511</td>\n    </tr>\n  </tbody>\n</table>\n<p>8965356 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"##### view a plot of the 2D features","metadata":{}},{"cell_type":"markdown","source":"### Determine number of clusters with elbow method\n\nIn determining number of clusters (k) let us vary the number of clusters ( K ) between 1 to 12. With each value of K, we calculate WCSS ( Within-Cluster Sum of Square ). WCSS is the sum of squared distance between each point and the centroid in a cluster. When we plot the WCSS with the K value, the plot looks like an Elbow. As the number of clusters increases, the WCSS value will start to decrease. WCSS value is largest when K = 1. When we analyze the graph we can see that the graph will rapidly change at a point and thus creating an elbow shape. From this point, the graph starts to move almost parallel to the X-axis. The K value corresponding to this point is the optimal K value or an optimal number of clusters.","metadata":{}},{"cell_type":"code","source":"###Decide n-cluster using Elbow Method\nwcss=[]\nk_range = range(1,12)\nfor i in k_range:\n    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n    kmeans.fit(scaled_df_train)\n    wcss.append(kmeans.inertia_)\nfig, ax = plt.subplots(figsize=(8, 6), dpi=80)\nplt.plot(k_range, wcss, marker='o')\n    \nplt.xticks(k_range)\n# plt.grid()\nplt.title('Elbow Method for Determining Optimal Value of k')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n# plt.savefig('num_clust.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:19:52.936377Z","iopub.execute_input":"2023-01-23T19:19:52.936723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confirm K number selection with knee locator\nkl = KneeLocator(range(1, 12), wcss, curve=\"convex\", direction=\"decreasing\")\nkl.elbow\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Optimal Value__ of k = 4","metadata":{}},{"cell_type":"markdown","source":"With this level of cleaning concluded, the model building and development stage follows next.","metadata":{}},{"cell_type":"markdown","source":"# Section 2: Model Development and Analysis\n\nThis section describes the steps and processes involved in building models for the project as well as the analysis of the model performance in terms of their accuracy in accomplishing the classification task.","metadata":{"id":"7e96f775"}},{"cell_type":"markdown","source":"# <a id=\"five\"></a>\n## 2.1 Modelling\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Modelling ⚡ |\n| :--------------------------- |\n| In this section, the **TeamNM3** team explored the following models for their skill and strengths with regards processing  was considered in the model development. The models include:\n\n- 1. L\n- 2. S \n---\nThe initial task is to build a base model using ...","metadata":{"id":"f09d8e4b"}},{"cell_type":"code","source":"def moviesListForUsers(users, users_data):\n    # users = a list of users IDs\n    # users_data = a dataframe of users favourite movies or users watched movies\n    users_movies_list = []\n    for user in users:\n        users_movies_list.append(str(list(users_data[users_data['userId'] == user]['movieId'])).split('[')[1].split(']')[0])\n    return users_movies_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The method moviesListForUsers returns us a list which will contain strings for each users favourite movies list. Later we will use CountVectorizer to extract the features of strings which contains list of movies.\n\nNote: The method moviesListForUsers returns us list in the same order as users list. So to avoid trap, we will have users list in the descending order.\n\nIn above defined method, we need to have a list of users and users_data dataframe. As users_data is the dataframe we already have. Now, let prepair the users list","metadata":{}},{"cell_type":"code","source":"users = np.unique(scaled_df_train['userId'])\nprint(users.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let prepair the list of movies list for each user.","metadata":{}},{"cell_type":"code","source":"users_movies_list = moviesListForUsers(users, scaled_df_train)\nprint('Movies list for', len(users_movies_list), ' users')\nprint('A list of first 10 users favourite movies: \\n', users_movies_list[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above is the list for first 10 users favourite movies list. First string contain first users favourite movies IDs, second for second users and so on. It looks that the list of 7th users favourite movies is larger than others.\n\nNow, we'll prepair a sparse matrix for each user against each movie\n\nIf user has watched movie then 1, else 0","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ndef prepSparseMatrix(list_of_str):\n    # list_of_str = A list, which contain strings of users favourite movies separate by comma \",\".\n    # It will return us sparse matrix and feature names on which sparse matrix is defined \n    # i.e. name of movies in the same order as the column of sparse matrix\n    cv = CountVectorizer(token_pattern = r'[^\\,\\ ]+', lowercase = False)\n    sparseMatrix = cv.fit_transform(list_of_str)\n    return sparseMatrix.toarray(), cv.get_feature_names()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sparseMatrix, feature_names = prepSparseMatrix(users_movies_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let put it into dataframe to have a more clear presentation. The format will be as columns will presents each movie and index will presents users IDs","metadata":{}},{"cell_type":"code","source":"df_sparseMatrix = pd.DataFrame(sparseMatrix, index = users, columns = feature_names)\ndf_sparseMatrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=4, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\nclusters = kmeans.fit_predict(sparseMatrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let’s evaluate how well the formed clusters are. To do that, we will calculate the inertia of the clusters:","metadata":{}},{"cell_type":"code","source":"# inertia on the fitted data\nkmeans.inertia_","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:04:17.309136Z","iopub.execute_input":"2023-01-23T18:04:17.309533Z","iopub.status.idle":"2023-01-23T18:04:17.316489Z","shell.execute_reply.started":"2023-01-23T18:04:17.309501Z","shell.execute_reply":"2023-01-23T18:04:17.315282Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"98375.35873391376"},"metadata":{}}]},{"cell_type":"markdown","source":"We got an inertia value of almost 98375. Now, let’s see how we can use the elbow curve to determine the optimum number of clusters in Python.\n\nWe will first fit multiple k-means models and in each successive model, we will increase the number of clusters. We will store the inertia value of each model and then plot it to visualize the result:","metadata":{}},{"cell_type":"code","source":"# fitting multiple k-means algorithms and storing the values in an empty list\nSSE = []\nfor cluster in range(1,10):\n    kmeans = KMeans(n_clusters = cluster, init='k-means++')\n    kmeans.fit(sparseMatrix)\n    SSE.append(kmeans.inertia_)\n\n# converting the results into a dataframe and plotting them\nframe = pd.DataFrame({'Cluster':range(1,10), 'SSE':SSE})\nplt.figure(figsize=(12,6))\nplt.plot(frame['Cluster'], frame['SSE'], marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:04:47.496071Z","iopub.execute_input":"2023-01-23T18:04:47.496503Z","iopub.status.idle":"2023-01-23T18:09:56.372394Z","shell.execute_reply.started":"2023-01-23T18:04:47.496452Z","shell.execute_reply":"2023-01-23T18:09:56.371249Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Text(0, 0.5, 'Inertia')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"users_cluster = pd.DataFrame(np.concatenate((users.reshape(-1,1), clusters.reshape(-1,1)), axis = 1), columns = ['userId', 'Cluster'])\nusers_cluster.T","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:10:30.362461Z","iopub.execute_input":"2023-01-23T18:10:30.362903Z","iopub.status.idle":"2023-01-23T18:10:30.393601Z","shell.execute_reply.started":"2023-01-23T18:10:30.362867Z","shell.execute_reply":"2023-01-23T18:10:30.392449Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"           0         1         2         3         4         5        6      \\\nuserId  -1.73294 -1.732919 -1.732833 -1.732812 -1.732748 -1.732684 -1.73262   \nCluster  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n\n            7         8         9      ...    56938     56939     56940  \\\nuserId  -1.732513 -1.732492 -1.732406  ...  1.73475  1.734793  1.734857   \nCluster  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000   \n\n            56941     56942    56943     56944     56945     56946     56947  \nuserId   1.734963  1.735049  1.73507  1.735091  1.735134  1.735155  1.735219  \nCluster  3.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n\n[2 rows x 56948 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>56938</th>\n      <th>56939</th>\n      <th>56940</th>\n      <th>56941</th>\n      <th>56942</th>\n      <th>56943</th>\n      <th>56944</th>\n      <th>56945</th>\n      <th>56946</th>\n      <th>56947</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>userId</th>\n      <td>-1.73294</td>\n      <td>-1.732919</td>\n      <td>-1.732833</td>\n      <td>-1.732812</td>\n      <td>-1.732748</td>\n      <td>-1.732684</td>\n      <td>-1.73262</td>\n      <td>-1.732513</td>\n      <td>-1.732492</td>\n      <td>-1.732406</td>\n      <td>...</td>\n      <td>1.73475</td>\n      <td>1.734793</td>\n      <td>1.734857</td>\n      <td>1.734963</td>\n      <td>1.735049</td>\n      <td>1.73507</td>\n      <td>1.735091</td>\n      <td>1.735134</td>\n      <td>1.735155</td>\n      <td>1.735219</td>\n    </tr>\n    <tr>\n      <th>Cluster</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 56948 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We define a function which will create a list of dataframes where each dataframe will contain the movieId and the counts for that movie (count: the number of users who has that respective movie in their favourite list). So, the movie which will have more counts will be of more interest to other users who has not watched that movie yet.\n\nFor Example, we'll create a list as following\n```[dataframe_for_Cluster_1, dataframe_for_Cluster_2, ..., dataframe_for_Cluster_3]```\nwhere 3rd column of Count is representing the total number of users in the cluster who have watched that particular movie. So, we will sort movies by their count in order to priortise the movie which have most seen by users in cluster and is more favourite for users in the cluster.\n\nNow we create a list of all user movies in each cluster. For this, first we'll define a method for creating movies of clusters.","metadata":{}},{"cell_type":"code","source":"def clustersMovies(users_cluster, users_data):\n    clusters = list(users_cluster['Cluster'])\n    each_cluster_movies = list()\n    for i in range(len(np.unique(clusters))):\n        users_list = list(users_cluster[users_cluster['Cluster'] == i]['userId'])\n        users_movies_list = list()\n        for user in users_list:    \n            users_movies_list.extend(list(users_data[users_data['userId'] == user]['movieId']))\n        users_movies_counts = list()\n        users_movies_counts.extend([[movie, users_movies_list.count(movie)] for movie in np.unique(users_movies_list)])\n        each_cluster_movies.append(pd.DataFrame(users_movies_counts, columns=['movieId', 'Count']).sort_values(by = ['Count'], ascending = False).reset_index(drop=True))\n    return each_cluster_movies","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:11:19.798470Z","iopub.execute_input":"2023-01-23T18:11:19.798906Z","iopub.status.idle":"2023-01-23T18:11:19.810376Z","shell.execute_reply.started":"2023-01-23T18:11:19.798855Z","shell.execute_reply":"2023-01-23T18:11:19.809384Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Now, let take a look at any one dataframe of cluster_movies.","metadata":{}},{"cell_type":"code","source":"cluster_movies = clustersMovies(users_cluster, scaled_df_train)\ncluster_movies[1].T","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:11:25.051344Z","iopub.execute_input":"2023-01-23T18:11:25.051810Z","iopub.status.idle":"2023-01-23T18:12:12.778062Z","shell.execute_reply.started":"2023-01-23T18:11:25.051772Z","shell.execute_reply":"2023-01-23T18:12:12.776970Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"               0         1         2         3         4         5    \\\nmovieId   -1.41884  1.773703 -0.900363 -0.148689 -1.126457 -0.742926   \nCount    157.00000  4.000000  4.000000  3.000000  3.000000  3.000000   \n\n              6         7         8        9    ...       204       205  \\\nmovieId -1.006899  0.498816  0.482244  0.46212  ... -0.515648 -0.514464   \nCount    3.000000  2.000000  2.000000  2.00000  ...  1.000000  1.000000   \n\n              206       207       208       209       210      211       212  \\\nmovieId -0.491973 -0.488422 -0.449358 -0.361762 -0.294289 -0.25049 -0.233918   \nCount    1.000000  1.000000  1.000000  1.000000  1.000000  1.00000  1.000000   \n\n              213  \nmovieId  2.009267  \nCount    1.000000  \n\n[2 rows x 214 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>204</th>\n      <th>205</th>\n      <th>206</th>\n      <th>207</th>\n      <th>208</th>\n      <th>209</th>\n      <th>210</th>\n      <th>211</th>\n      <th>212</th>\n      <th>213</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>movieId</th>\n      <td>-1.41884</td>\n      <td>1.773703</td>\n      <td>-0.900363</td>\n      <td>-0.148689</td>\n      <td>-1.126457</td>\n      <td>-0.742926</td>\n      <td>-1.006899</td>\n      <td>0.498816</td>\n      <td>0.482244</td>\n      <td>0.46212</td>\n      <td>...</td>\n      <td>-0.515648</td>\n      <td>-0.514464</td>\n      <td>-0.491973</td>\n      <td>-0.488422</td>\n      <td>-0.449358</td>\n      <td>-0.361762</td>\n      <td>-0.294289</td>\n      <td>-0.25049</td>\n      <td>-0.233918</td>\n      <td>2.009267</td>\n    </tr>\n    <tr>\n      <th>Count</th>\n      <td>157.00000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 214 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"2 rows × 16 columns\n\n\n\nNow, let see how much users we have in each cluster","metadata":{}},{"cell_type":"code","source":"for i in range(4):\n    len_users = users_cluster[users_cluster['Cluster'] == i].shape[0]\n    print('Users in Cluster ' + str(i) + ' -> ', len_users)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:12:22.677797Z","iopub.execute_input":"2023-01-23T18:12:22.678174Z","iopub.status.idle":"2023-01-23T18:12:22.700219Z","shell.execute_reply.started":"2023-01-23T18:12:22.678145Z","shell.execute_reply":"2023-01-23T18:12:22.699007Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Users in Cluster 0 ->  55605\nUsers in Cluster 1 ->  157\nUsers in Cluster 2 ->  667\nUsers in Cluster 3 ->  519\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Observe that clusters 1, 2, 3 have 1, 6 and 11 users respectively. There is need to fix such small clusters.\n\n__Fixing Small Clusters__\n\nWe write a function to get user favourite movies list","metadata":{}},{"cell_type":"code","source":"def getMoviesOfUser(user_id, users_data):\n    return list(users_data[users_data['userId'] == user_id]['movieId'])","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:12:31.786805Z","iopub.execute_input":"2023-01-23T18:12:31.787209Z","iopub.status.idle":"2023-01-23T18:12:31.792284Z","shell.execute_reply.started":"2023-01-23T18:12:31.787176Z","shell.execute_reply":"2023-01-23T18:12:31.791039Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"define a function for fixing clusters","metadata":{}},{"cell_type":"code","source":"def fixClusters(clusters_movies_dataframes, users_cluster_dataframe, users_data, smallest_cluster_size = 11):\n    # clusters_movies_dataframes: will be a list which will contain each dataframes of each cluster movies\n    # users_cluster_dataframe: will be a dataframe which contain users IDs and their cluster no.\n    # smallest_cluster_size: is a smallest cluster size which we want for a cluster to not remove\n    each_cluster_movies = clusters_movies_dataframes.copy()\n    users_cluster = users_cluster_dataframe.copy()\n    # Let convert dataframe in each_cluster_movies to list with containing only movies IDs\n    each_cluster_movies_list = [list(df['movieId']) for df in each_cluster_movies]\n    # First we will prepair a list which containt lists of users in each cluster -> [[Cluster 0 Users], [Cluster 1 Users], ... ,[Cluster N Users]] \n    usersInClusters = list()\n    total_clusters = len(each_cluster_movies)\n    for i in range(total_clusters):\n        usersInClusters.append(list(users_cluster[users_cluster['Cluster'] == i]['userId']))\n    uncategorizedUsers = list()\n    i = 0\n    # Now we will remove small clusters and put their users into another list named \"uncategorizedUsers\"\n    # Also when we will remove a cluster, then we have also bring back cluster numbers of users which comes after deleting cluster\n    # E.g. if we have deleted cluster 4 then their will be users whose clusters will be 5,6,7,..,N. So, we'll bring back those users cluster number to 4,5,6,...,N-1.\n    for j in range(total_clusters):\n        if len(usersInClusters[i]) < smallest_cluster_size:\n            uncategorizedUsers.extend(usersInClusters[i])\n            usersInClusters.pop(i)\n            each_cluster_movies.pop(i)\n            each_cluster_movies_list.pop(i)\n            users_cluster.loc[users_cluster['Cluster'] > i, 'Cluster'] -= 1\n            i -= 1\n        i += 1\n    for user in uncategorizedUsers:\n        elemProbability = list()\n        user_movies = getMoviesOfUser(user, users_data)\n        if len(user_movies) == 0:\n            print(user)\n        user_missed_movies = list()\n        for movies_list in each_cluster_movies_list:\n            count = 0\n            missed_movies = list()\n            for movie in user_movies:\n                if movie in movies_list:\n                    count += 1\n                else:\n                    missed_movies.append(movie)\n            elemProbability.append(count / len(user_movies))\n            user_missed_movies.append(missed_movies)\n        user_new_cluster = np.array(elemProbability).argmax()\n        users_cluster.loc[users_cluster['userId'] == user, 'Cluster'] = user_new_cluster\n        if len(user_missed_movies[user_new_cluster]) > 0:\n            each_cluster_movies[user_new_cluster] = each_cluster_movies[user_new_cluster].append([{'movieId': new_movie, 'Count': 1} for new_movie in user_missed_movies[user_new_cluster]], ignore_index = True)\n    return each_cluster_movies, users_cluster","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:12:36.523439Z","iopub.execute_input":"2023-01-23T18:12:36.523865Z","iopub.status.idle":"2023-01-23T18:12:36.540618Z","shell.execute_reply.started":"2023-01-23T18:12:36.523830Z","shell.execute_reply":"2023-01-23T18:12:36.539307Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"movies_df_fixed, clusters_fixed = fixClusters(cluster_movies, users_cluster, scaled_df_train, smallest_cluster_size = 6)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:12:38.098366Z","iopub.execute_input":"2023-01-23T18:12:38.098781Z","iopub.status.idle":"2023-01-23T18:12:38.116244Z","shell.execute_reply.started":"2023-01-23T18:12:38.098747Z","shell.execute_reply":"2023-01-23T18:12:38.115434Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"\n\nNow let take a look at list of movies dataframes","metadata":{}},{"cell_type":"code","source":"print('Size of movies dataframe after fixing -> ', len(movies_df_fixed))","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:12:41.451706Z","iopub.execute_input":"2023-01-23T18:12:41.452761Z","iopub.status.idle":"2023-01-23T18:12:41.459969Z","shell.execute_reply.started":"2023-01-23T18:12:41.452724Z","shell.execute_reply":"2023-01-23T18:12:41.458890Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Size of movies dataframe after fixing ->  4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, lets look at the sizes of clusters","metadata":{}},{"cell_type":"code","source":"for i in range(len(movies_df_fixed)):\n    len_users = clusters_fixed[clusters_fixed['Cluster'] == i].shape[0]\n    print('Users in Cluster ' + str(i) + ' -> ', len_users)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:12:44.650245Z","iopub.execute_input":"2023-01-23T18:12:44.650668Z","iopub.status.idle":"2023-01-23T18:12:44.666956Z","shell.execute_reply.started":"2023-01-23T18:12:44.650632Z","shell.execute_reply":"2023-01-23T18:12:44.665806Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Users in Cluster 0 ->  55605\nUsers in Cluster 1 ->  157\nUsers in Cluster 2 ->  667\nUsers in Cluster 3 ->  519\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Each cluster is now containing enough users so that we can make recommendations for other users. Let take a look at each size of clusters movies list.","metadata":{}},{"cell_type":"code","source":"for i in range(len(movies_df_fixed)):\n    print('Total movies in Cluster ' + str(i) + ' -> ', movies_df_fixed[i].shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:12:48.973428Z","iopub.execute_input":"2023-01-23T18:12:48.973832Z","iopub.status.idle":"2023-01-23T18:12:48.985033Z","shell.execute_reply.started":"2023-01-23T18:12:48.973799Z","shell.execute_reply":"2023-01-23T18:12:48.983780Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Total movies in Cluster 0 ->  2498\nTotal movies in Cluster 1 ->  214\nTotal movies in Cluster 2 ->  369\nTotal movies in Cluster 3 ->  414\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As, we have done working with training machine learning model k-means, making predictions of clusters for each user and fixing some issues. Finally, we need to store this training so that we can use it later. For this, we will Pickle liabrary to save and load trainings. We have already imported Pickle, now we will use it.\n\nLet me first design object to save and load trainings. We will directly design methods for saving/loading particular files and also we will design general save/load methods","metadata":{}},{"cell_type":"markdown","source":"__Predict__\n\nWe now predict the test dataset","metadata":{}},{"cell_type":"code","source":"\ntest_scaled = ss.fit_transform(df_test)\nscaled_df_test = pd.DataFrame(test_scaled, columns=['userId', 'movieId'])\nscaled_df_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users_test = np.unique(scaled_df_test['userId'])\nprint(users.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users_movies_list_test = moviesListForUsers(users_test, scaled_df_test)\nprint('Movies list for', len(users_movies_list_test), ' users')\nprint('A list of first 10 users favourite movies: \\n', users_movies_list_test[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sparseMatrix_test, feature_names_test = prepSparseMatrix(users_movies_list_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clusters_test = kmeans.fit(sparseMatrix_test)\nclusters_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters = 9, init='k-means++')\npred_test = kmeans.fit_predict(sparseMatrix_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.1 Overview of the Selected Models","metadata":{}},{"cell_type":"markdown","source":"### 2.1.2 Fit, Train and Predict with a base model\nThe first step of modeling involved fitting, training and predicting a base model of ...","metadata":{}},{"cell_type":"markdown","source":"### DISCUSSION\nThe two outputs above are ","metadata":{}},{"cell_type":"markdown","source":"### 2.1.3 Building other models \nWith the base model fully operational, it is now reasonable to develop other models that can strengthen the recommendation system task. As with all the earlier stages of the data science process, functions are built to help enhance the functionality of training and testing the datasets.","metadata":{}},{"cell_type":"markdown","source":"#### 2.1.3.1 Create model objects for all models","metadata":{}},{"cell_type":"markdown","source":"#### 2.1.3.2 Create functions for training and testing all models\nTwo functions `train_model` and `test_model` are created to optimize the process of training and testing all selected models.","metadata":{}},{"cell_type":"code","source":"# create a function to train our models\ndef train_model(model, X, y):\n\n    ''' returns a model trained on the training dataset\n        parameters:\n            model:   a machine learning model\n            X:\n    '''    \n    return model.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.4 Model Fitting, Training and Predictions\n\nThe models are fitted and trained on the balanced datasets and then used for predicting the tweet classification task on the unseen dataset. The process involves using the trained models by calling on built functions. \n\nFirst, the prediction is done with the validation dataset which has a label but has not been resampled. This prediction results are used in the next sub-section for evaluating the model performance. Another prediction set is conducted subsequently on the blind test dataset which has no labels. This prediction is used for the Kaggle submission to obtain external scores on the performance of the models.","metadata":{}},{"cell_type":"markdown","source":"#### 2.1.4.1 Model 1: ","metadata":{}},{"cell_type":"code","source":"# training the ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.1.4.2 Model 2: ","metadata":{}},{"cell_type":"code","source":"# training the support vector machine \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.5 Extract Results for Submission\nWith the model fitting, training and prediction tasks completed, it is now possible to extract results from some of the models for submission on Kaggle as well as for use in Streamlit web app development.","metadata":{}},{"cell_type":"markdown","source":"#### Extracting Results for Submission - Kaggle","metadata":{}},{"cell_type":"code","source":"df_test.index","metadata":{"execution":{"iopub.status.busy":"2023-01-23T19:06:45.951161Z","iopub.execute_input":"2023-01-23T19:06:45.951602Z","iopub.status.idle":"2023-01-23T19:06:45.959116Z","shell.execute_reply.started":"2023-01-23T19:06:45.951543Z","shell.execute_reply":"2023-01-23T19:06:45.957973Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"RangeIndex(start=0, stop=5000019, step=1)"},"metadata":{}}]},{"cell_type":"code","source":"#create a Kaggle submission file for the model\nresults_dict = pd.DataFrame({'userId':df_test['userId'],\n                'movieId': pred_test})\n\nresults_dict.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Extracting pkl file for web app development","metadata":{}},{"cell_type":"code","source":"# pickle/save base model for Streamlit web deployment\nmodel_save_path = \"k-means.pkl\"\nwith open(model_save_path,'wb') as file:\n    pickle.dump(pred_test,file)","metadata":{"execution":{"iopub.status.busy":"2023-01-23T18:47:30.612950Z","iopub.execute_input":"2023-01-23T18:47:30.613395Z","iopub.status.idle":"2023-01-23T18:47:30.619149Z","shell.execute_reply.started":"2023-01-23T18:47:30.613362Z","shell.execute_reply":"2023-01-23T18:47:30.618017Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"six\"></a>\n## 2.2 Model Performance\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Model performance ⚡ |\n| :--------------------------- |\n| In this section, the relative performance of the selected classification models against some common metrics are compared and considered. The following metrics are deployed in checking the model performance using functions, as previously established:\n-  |\n\n---\n**xxx**\n\n.\n","metadata":{"id":"db888d19"}},{"cell_type":"markdown","source":"### 2.2.1 Model Scores, Matrices and Heatmaps\nA function is built to take care of the `roc_auc_score` calculation.","metadata":{}},{"cell_type":"code","source":"# define a function for calculating roc scores\ndef roc_score(model, X_valid, y_valid):    \n    # with the model previously instantiated, \n\n    return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.2.1.1 Scores and Matrices of models trained on the balanced training dataset\nThe scores of models trained on the resampled datasets are first verified and then tabulated and plotted for easy comparison.","metadata":{}},{"cell_type":"markdown","source":"#### Model 1: ","metadata":{}},{"cell_type":"code","source":"# print roc_score for xxx model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 2: Support Vector","metadata":{}},{"cell_type":"code","source":"# plot bar of roc\nroc_factsheet.plot(kind='bar', title='ROC scores across selected xxx')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DISCUSSION\nIn the simple barplot of the ROC scores above, ","metadata":{}},{"cell_type":"markdown","source":"### DISCUSSION\nIn this instance,","metadata":{}},{"cell_type":"markdown","source":"### 2.2.2 Improving model performance","metadata":{}},{"cell_type":"markdown","source":"The results above ...","metadata":{}},{"cell_type":"markdown","source":"#### 2.2.2.1 Implementing Hyperparameter tuning to improve model performance","metadata":{}},{"cell_type":"markdown","source":"# Section 3: Model Explanations and Conclusions\n\nThis section describes","metadata":{"id":"12dc0afd"}},{"cell_type":"markdown","source":"<a id=\"seven\"></a>\n## 3.1 Model Explanation\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Model explanation ⚡ |\n| :--------------------------- |\n| In this section, we discuss the inner workings of some of the selected models work in an attempt to understand how the models have performed the task. We discuss the following models:\n- \n- Support Vector Machines,\n- Random Forest.|\n\n---","metadata":{"id":"63dcea8f"}},{"cell_type":"markdown","source":"### 3.1.1 Understanding the inner workings of select models","metadata":{}},{"cell_type":"markdown","source":"### 3.1.2 Characteristics and Advantages of the Best Performing Models","metadata":{}},{"cell_type":"markdown","source":"<a id=\"seven\"></a>\n## 3.2 Conclusions\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| ⚡ Description: Model explanation ⚡ |\n| :--------------------------- |\n| In this section, we draw conclusions and consider a few recommendations based on the discussions and investigations conducted for this Twitter classification project.|\n\n---","metadata":{"id":"995e6112"}},{"cell_type":"markdown","source":"In conclusion, it can be said that:\n- the data available from the \n\nFinally, it is evident that deploying machine learning solutions that are well-tuned to \n\nThus, thorough consideration of the strategic objectives and direction of the company with regards to interventions to be supported by insights from the ... can improve the choice of the machine learning model that best delivers on the recommendation system task.","metadata":{}},{"cell_type":"markdown","source":"### 3.2.1 Logging and extracting parameters for Comet experiments","metadata":{}},{"cell_type":"code","source":"# create dictionaries for the data we want to log\n\n# metrics\nmetrics_nbc_smt = {\"f1\": nbc_smt_f1, \"recall\": nbc_smt_r, \n                  \"precision\": nbc_smt_p, \"roc\": nbc_roc}\n\n# parameters\nparams_nbc_smt = {\"vectorizer\": tf_vect, \"model_type\": \"naive bayes\", \n                 \"model\": nbc_smt, \"robust scaler\": rs, \"Min Max\": mm}\n\n#params_abc_sm = {\"random_state\": 42, \"vectorizer\": tf_vect, \n #                \"model_type\": \"ada boost\", \"model\": abc_sm, \n #                \"robust scaler\": rs, \"Min Max\": mm, \n #                 \"base_estimator\": rfc}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log our parameters and results\nexperiment.log_parameters(params_nbc_smt)\nexperiment.log_metrics(metrics_nbc_smt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# end the experiment on Comet\nexperiment.end()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Running experiment.display() will show the experiments comet.ml page","metadata":{}},{"cell_type":"code","source":"# display the experiment parameters on Comet\nexperiment.display()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}